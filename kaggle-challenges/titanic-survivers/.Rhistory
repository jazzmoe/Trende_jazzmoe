#### EDA: exploratory data analysis
apply(names(Train),2, table)
#### EDA: exploratory data analysis
apply(Train,2, table)
#### EDA: exploratory data analysis
lapply(Train,2, table)
#### EDA: exploratory data analysis
lapply(Train, table)
names(Train)
#### EDA: exploratory data analysis
lapply(Train[,c("survived", "pclass", "sex", "sibsp", "parch", "embarked")], table)
342/549
a <- sample(c(0,1), 418, replace = TRUE, prob = c(1-0.623, 0.623))
a
accuracy(Train$survived, survML)
# ML estimator | P(y = 1) = 0.623
survML <- sample(c(0,1), 418, replace = TRUE, prob = c(1-0.623, 0.623))
accuracy(Train$survived, survML)
# ML estimator | P(y = 1) = 0.623
survML <- sample(c(0,1), 891, replace = TRUE, prob = c(1-0.623, 0.623))
accuracy(Train$survived, survML)
data(GermanCredit)
mod_fit <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own +
CreditHistory.Critical,  data=training, method="glm", family="binomial")
data(GermanCredit)
Train <- createDataPartition(GermanCredit$Class, p=0.6, list=FALSE)
training <- GermanCredit[ Train, ]
testing <- GermanCredit[ -Train, ]
mod_fit <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own +
CreditHistory.Critical,  data=training, method="glm", family="binomial")
pred = predict(mod_fit, newdata=testing)
accuracy <- table(pred, testing[,"Class"])
accuracy
pred = predict(mod_fit, newdata=testing)
pred
predict(Mod3)
trainData <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit)
confusionMatrix(Mod3)
print(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
Mod3.pred <- ifelse(predict(Mod3, newdata = Test, type = "prob") > 0.5, 1, 0) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
predict(Mod3)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit)
########################################
### Kaggle Challenge: Titanic Survivers
########################################
### Outline
########################################
### Setup
source("packages.R")
source("functions.R")
# install.packages('e1071', dependencies=TRUE)
############
### Code ###
############
### Load data
Train <- read_csv("./data/train.csv")
Test <- read_csv("./data/test.csv")
SubTemp <- read_csv("./data/gender_submission.csv")
# Variable Notes
# pclass: A proxy for socio-economic status (SES)
# 1st = Upper
# 2nd = Middle
# 3rd = Lower
#
# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5
#
# sibsp: The dataset defines family relations in this way...
# Sibling = brother, sister, stepbrother, stepsister
# Spouse = husband, wife (mistresses and fiancés were ignored)
#
# parch: The dataset defines family relations in this way...
# Parent = mother, father
# Child = daughter, son, stepdaughter, stepson
# Some children travelled only with a nanny, therefore parch=0 for them.
### Data prep
names(Train) <- str_to_lower(names(Train))
names(Test) <- str_to_lower(names(Test))
Train <- Train %>% mutate(survived = as.factor(survived))
glimpse(Train)
# define test and training in test set
TrainTest <- sample_n(Train, size = round(0.2*(nrow(Train))))
TrainTrain <- Train[!(Train$passengerid %in% TrainTest$passengerid),]
#### EDA: exploratory data analysis
lapply(Train[,c("survived", "pclass", "sex", "sibsp", "parch", "embarked")], table)
table
Train %>% ggplot() + geom_histogram(aes(x = age))
Train %>% ggplot() + geom_histogram(aes(x = fare))
Train %>% ggplot() + geom_bar(aes(x = sex))
Train %>% ggplot() + geom_bar(aes(x = pclass))
table(Train$sibsp, Train$survived)
chisq.test(Train$sibsp, Train$survived) # significant relationship
# ML estimator | P(y = 1) = 0.623
survML <- sample(c(0,1), 891, replace = TRUE, prob = c(1-0.623, 0.623))
accuracy(Train$survived, survML)
### Simple logistic regression
Mod1 <- glm(survived ~ sex + fare, data = TrainTrain, family = "binomial", na.action = na.omit)
TrainTest <- TrainTest %>% mutate(
surv.mod1 = ifelse(predict(Mod1, newdata = TrainTest, type = "response") > 0.6, 1, 0),
surv.mod1 = ifelse(is.na(surv.mod1), 0, identity(surv.mod1)))
accuracy(TrainTest$survived, TrainTest$surv.mod1)
# alternative / full model
Mod1.1 <- glm(survived ~ sex + fare + pclass + age, data = TrainTrain, family = "binomial")
TrainTest <- TrainTest %>% mutate(
surv.mod1.1 = ifelse(predict(Mod1.1, newdata = TrainTest, type = "response") > 0.6, 1, 0),
surv.mod1.1 = ifelse(is.na(surv.mod1), 0, identity(surv.mod1)))
accuracy(TrainTest$survived, TrainTest$surv.mod1.1)
anova(Mod1, Mod1.1)
### random effects model
Mod2 <- glmer(survived ~ sex + fare + sibsp + (1 | pclass), data = TrainTrain, family = binomial)
summary(Mod2)
TrainTest <- TrainTest %>% mutate(
surv.mod2 = ifelse(predict(Mod2, newdata = TrainTest, type = "response") > 0.6, 1, 0))
accuracy(TrainTest$survived, TrainTest$surv.mod2)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit)
confusionMatrix(Mod3)
print(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
Mod3.pred <- ifelse(predict(Mod3, newdata = Test, type = "prob") > 0.5, 1, 0) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
source("packages.R")
source("functions.R")
### Load data
Train <- read_csv("./data/train.csv")
Test <- read_csv("./data/test.csv")
SubTemp <- read_csv("./data/gender_submission.csv")
### Data prep
names(Train) <- str_to_lower(names(Train))
names(Test) <- str_to_lower(names(Test))
Train <- Train %>% mutate(survived = as.factor(survived))
glimpse(Train)
# define test and training in test set
TrainTest <- sample_n(Train, size = round(0.2*(nrow(Train))))
########################################
### Kaggle Challenge: Titanic Survivers
########################################
### Outline
########################################
### Setup
source("packages.R")
source("functions.R")
# install.packages('e1071', dependencies=TRUE)
############
### Code ###
############
### Load data
Train <- read_csv("./data/train.csv")
Test <- read_csv("./data/test.csv")
SubTemp <- read_csv("./data/gender_submission.csv")
# Variable Notes
# pclass: A proxy for socio-economic status (SES)
# 1st = Upper
# 2nd = Middle
# 3rd = Lower
#
# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5
#
# sibsp: The dataset defines family relations in this way...
# Sibling = brother, sister, stepbrother, stepsister
# Spouse = husband, wife (mistresses and fiancés were ignored)
#
# parch: The dataset defines family relations in this way...
# Parent = mother, father
# Child = daughter, son, stepdaughter, stepson
# Some children travelled only with a nanny, therefore parch=0 for them.
### Data prep
names(Train) <- str_to_lower(names(Train))
names(Test) <- str_to_lower(names(Test))
Train <- Train %>% mutate(survived = as.factor(survived))
glimpse(Train)
# define test and training in test set
Testing <- sample_n(Train, size = round(0.2*(nrow(Train))))
Training <- Train[!(Train$passengerid %in% Testing$passengerid),]
#### EDA: exploratory data analysis
lapply(Train[,c("survived", "pclass", "sex", "sibsp", "parch", "embarked")], table)
table
Train %>% ggplot() + geom_histogram(aes(x = age))
Train %>% ggplot() + geom_histogram(aes(x = fare))
Train %>% ggplot() + geom_bar(aes(x = sex))
Train %>% ggplot() + geom_bar(aes(x = pclass))
table(Train$sibsp, Train$survived)
chisq.test(Train$sibsp, Train$survived) # significant relationship
# ML estimator | P(y = 1) = 0.623
survML <- sample(c(0,1), 891, replace = TRUE, prob = c(1-0.623, 0.623))
accuracy(Train$survived, survML)
### Simple logistic regression
Mod1 <- glm(survived ~ sex + fare, data = Training, family = "binomial", na.action = na.omit)
Testing <- Testing %>% mutate(
surv.mod1 = ifelse(predict(Mod1, newdata = Testing, type = "response") > 0.6, 1, 0),
surv.mod1 = ifelse(is.na(surv.mod1), 0, identity(surv.mod1)))
accuracy(Testing$survived, Testing$surv.mod1)
predict(Mod1, Testing)
varImp(Mod3)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
confusionMatrix(Mod3)
print(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
confusionMatrix(Mod3)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, repeats = 3)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
confusionMatrix(Mod3)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, repeats = 3)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Training, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
predict(Mod3, newdata = Testing)
confusionMatrix(Mod3)
confusionMatrix(Mod3)
confusionMatrix(Mod3)
print(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
accuracy(predict(Mod3, newdata = Testing), Testing$survived)
Testing$survived
predict(Mod3, newdata = Testing)
predict(Mod3)
predict(Mod3)
predict(Mod3, Training)
accuracy(predict(Mod3, Training), Training$survived)
predict(Mod3, Training)
Training$survived
confusionMatrix(Mod3)
print(Mod3)
Mod3.pred <- ifelse(predict(Mod3, newdata = Test, type = "prob") > 0.5, 1, 0) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
predict(Mod3, newdata = Test)
nrow(predict(Mod3, newdata = Test)
nrow(predict(Mod3, newdata = Test))
length(predict(Mod3, newdata = Test))
table(Test$age, useNA = "ifany")
418-86
?predict
?fitted.values
predict(Mod3, newdata = Test, type = "prob")
nrow(predict(Mod3, newdata = Test, type = "prob"))
nrow(predict(Mod3, newdata = Test, type = "prob"))
predict(Mod3, newdata = Test, type = "prob")
a <- predict(Mod3, newdata = Test, type = "prob")
View(a)
a <- predict(Mod3, newdata = Test)
length(a)
varImp(Mod3)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Training, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.exclude, tuneLength = 5)
confusionMatrix(Mod3)
print(Mod3)
Mod3.pred <- ifelse(predict(Mod3, newdata = Test, type = "prob") > 0.5, 1, 0) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
predict(Mod3)
varImp(Mod3)
a <- predict(Mod3, newdata = Test)
length(a)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Training, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
confusionMatrix(Mod3)
print(Mod3)
Mod3.pred <- ifelse(predict(Mod3, newdata = Test, type = "prob") > 0.5, 1, 0) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
predict(Mod3)
### create classification vector
Bench <- cbind(SubTemp, modpred = Mod3.pred$Survived)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Training, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit)
predict(Mod3, newdata = Test)
View(Mod3.pred)
### create classification vector
Bench <- cbind(SubTemp, modpred = Mod3.pred$Survived)
########################################
### Kaggle Challenge: Titanic Survivers
########################################
### Outline
########################################
### Setup
source("packages.R")
source("functions.R")
# install.packages('e1071', dependencies=TRUE)
############
### Code ###
############
### Load data
Train <- read_csv("./data/train.csv")
Test <- read_csv("./data/test.csv")
SubTemp <- read_csv("./data/gender_submission.csv")
# Variable Notes
# pclass: A proxy for socio-economic status (SES)
# 1st = Upper
# 2nd = Middle
# 3rd = Lower
#
# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5
#
# sibsp: The dataset defines family relations in this way...
# Sibling = brother, sister, stepbrother, stepsister
# Spouse = husband, wife (mistresses and fiancés were ignored)
#
# parch: The dataset defines family relations in this way...
# Parent = mother, father
# Child = daughter, son, stepdaughter, stepson
# Some children travelled only with a nanny, therefore parch=0 for them.
### Data prep
names(Train) <- str_to_lower(names(Train))
names(Test) <- str_to_lower(names(Test))
Train <- Train %>% mutate(survived = as.factor(survived))
glimpse(Train)
# define test and training in test set
TrainTest <- sample_n(Train, size = round(0.2*(nrow(Train))))
TrainTrain <- Train[!(Train$passengerid %in% TrainTest$passengerid),]
#### EDA: exploratory data analysis
Train %>% ggplot() + geom_histogram(aes(x = age))
Train %>% ggplot() + geom_histogram(aes(x = fare))
Train %>% ggplot() + geom_bar(aes(x = sex))
Train %>% ggplot() + geom_bar(aes(x = pclass))
table(Train$sibsp, Train$survived)
chisq.test(Train$sibsp, Train$survived) # significant relationship
### Simple logistic regression
Mod1 <- glm(survived ~ sex + fare, data = TrainTrain, family = "binomial", na.action = na.omit)
TrainTest <- TrainTest %>% mutate(
surv.mod1 = ifelse(predict(Mod1, newdata = TrainTest, type = "response") > 0.6, 1, 0),
surv.mod1 = ifelse(is.na(surv.mod1), 0, identity(surv.mod1)))
accuracy(TrainTest$survived, TrainTest$surv.mod1)
# alternative / full model
Mod1.1 <- glm(survived ~ sex + fare + pclass + age, data = TrainTrain, family = "binomial")
TrainTest <- TrainTest %>% mutate(
surv.mod1.1 = ifelse(predict(Mod1.1, newdata = TrainTest, type = "response") > 0.6, 1, 0),
surv.mod1.1 = ifelse(is.na(surv.mod1), 0, identity(surv.mod1)))
accuracy(TrainTest$survived, TrainTest$surv.mod1.1)
### random effects model
Mod2 <- glmer(survived ~ sex + fare + sibsp + (1 | pclass), data = TrainTrain, family = binomial)
summary(Mod2)
TrainTest <- TrainTest %>% mutate(
surv.mod2 = ifelse(predict(Mod2, newdata = TrainTest, type = "response") > 0.6, 1, 0))
accuracy(TrainTest$survived, TrainTest$surv.mod2)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "cv", number = 10, savePredictions = TRUE)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit)
confusionMatrix(Mod3)
print(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
Mod3.pred <- ifelse(predict(Mod3, newdata = Test, type = "prob") > 0.5, 1, 0) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
### create forecast
Bench <- cbind(SubTemp, modpred = Mod3.pred$Survived)
confusionMatrix(Mod3)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 10)
confusionMatrix(Mod3)
print(Mod3)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, repeats = 3)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, repeats = 5)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Train, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
confusionMatrix(Mod3)
print(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
Mod3.pred <- predict(Mod3, newdata = Test) %>%
as_tibble() %>% rename("Died" = `0`, "Survived" = `1`)
predict(Mod3, newdata = Test)
Mod3.pred <- predict(Mod3, newdata = Test)
confusionMatrix(Mod3)
accuracy(Mod3$pred$pred, Mod3$pred$obs)
########################################
### Kaggle Challenge: Titanic Survivers
########################################
### Outline
########################################
### Setup
source("packages.R")
source("functions.R")
# install.packages('e1071', dependencies=TRUE)
############
### Code ###
############
### Load data
Train <- read_csv("./data/train.csv")
Test <- read_csv("./data/test.csv")
SubTemp <- read_csv("./data/gender_submission.csv")
# Variable Notes
# pclass: A proxy for socio-economic status (SES)
# 1st = Upper
# 2nd = Middle
# 3rd = Lower
#
# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5
#
# sibsp: The dataset defines family relations in this way...
# Sibling = brother, sister, stepbrother, stepsister
# Spouse = husband, wife (mistresses and fiancés were ignored)
#
# parch: The dataset defines family relations in this way...
# Parent = mother, father
# Child = daughter, son, stepdaughter, stepson
# Some children travelled only with a nanny, therefore parch=0 for them.
### Data prep
names(Train) <- str_to_lower(names(Train))
names(Test) <- str_to_lower(names(Test))
Train <- Train %>% mutate(survived = as.factor(survived))
glimpse(Train)
# define test and training in test set
Testing <- sample_n(Train, size = round(0.2*(nrow(Train))))
Training <- Train[!(Train$passengerid %in% Testing$passengerid),]
#### EDA
Mod3.pred <- predict(Mod3, newdata = Testing)
length(Mod3.pred)
Testing$survived[which(!is.na(Testing$survived))]
length(Mod3.pred)
accuracy(Testing$survived[which(!is.na(Testing$age))], Mod3.pred)
# good source https://www.r-bloggers.com/evaluating-logistic-regression-models/
### machine learning logit (caret)
trainData <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE, repeats = 5)
Mod3 <- train(survived ~ sex + pclass + age + sibsp + parch + fare,
data = Training, trControl = trainData, method = "rf", nTree = 100,
metric = "Accuracy", na.action = na.omit, tuneLength = 5)
print(Mod3)
# test on Testing (without age)
Mod3.pred <- predict(Mod3, newdata = Testing)
accuracy(Testing$survived[which(!is.na(Testing$age))], Mod3.pred)
#### EDA: exploratory data analysis
p1 <- Train %>% ggplot() + geom_histogram(aes(x = age))
p2 <- Train %>% ggplot() + geom_histogram(aes(x = fare))
p3 <- Train %>% ggplot() + geom_bar(aes(x = sex))
p4 <- Train %>% ggplot() + geom_bar(aes(x = pclass))
########################################
### Kaggle Challenge: Titanic Survivers
########################################
### Outline
########################################
### Setup
source("packages.R")
source("functions.R")
# install.packages('e1071', dependencies=TRUE)
############
### Code ###
############
### Load data
Train <- read_csv("./data/train.csv")
Test <- read_csv("./data/test.csv")
SubTemp <- read_csv("./data/gender_submission.csv")
# Variable Notes
# pclass: A proxy for socio-economic status (SES)
# 1st = Upper
# 2nd = Middle
# 3rd = Lower
#
# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5
#
# sibsp: The dataset defines family relations in this way...
# Sibling = brother, sister, stepbrother, stepsister
# Spouse = husband, wife (mistresses and fiancés were ignored)
#
# parch: The dataset defines family relations in this way...
# Parent = mother, father
# Child = daughter, son, stepdaughter, stepson
# Some children travelled only with a nanny, therefore parch=0 for them.
### Data prep
names(Train) <- str_to_lower(names(Train))
names(Test) <- str_to_lower(names(Test))
Train <- Train %>% mutate(survived = as.factor(survived))
glimpse(Train)
### define test and training in test set; also: createResample() or createFolds()
Testing <- sample_n(Train, size = round(0.2*(nrow(Train))))
Training <- Train[!(Train$passengerid %in% Testing$passengerid),]
#### EDA: exploratory data analysis
p1 <- Train %>% ggplot() + geom_histogram(aes(x = age))
p2 <- Train %>% ggplot() + geom_histogram(aes(x = fare))
p3 <- Train %>% ggplot() + geom_bar(aes(x = sex))
p4 <- Train %>% ggplot() + geom_bar(aes(x = pclass))
?geom_boxplot
p4 <- Train %>% ggplot() + geom_boxplot(aes(pclass, fare))
p4
p4 <- Train %>% ggplot() + geom_boxplot(aes(pclass, fare), group = pclass)
p4 <- Train %>% ggplot() + geom_boxplot(aes(pclass, fare, , group = pclass))
p4 <- Train %>% ggplot() + geom_boxplot(aes(pclass, fare, group = pclass))
p4
